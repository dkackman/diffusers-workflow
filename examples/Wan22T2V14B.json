{
    "id": "Wan22T2V14B",
    "variables": {
        "model_name": "Wan-AI/Wan2.2-T2V-A14B-Diffusers",
        "prompt": "Over-the-shoulder shot. A man in a white shirt and brown vest stands, A man in a white shirt and a brown vest stands by a fireplace, looking at someone to the right.",
        "num_inference_steps": 40
    },
    "steps": [
        {
            "name": "text_to_video",
            "pipeline": {
                "configuration": {
                    "component_type": "WanPipeline",
                    "offload": "model"
                },
                "vae": {
                    "configuration": {
                        "component_type": "AutoencoderKLWan",
                        "device": "cpu"
                    },
                    "from_pretrained_arguments": {
                        "model_name": "variable:model_name",
                        "subfolder": "vae",
                        "torch_dtype": "torch.float32"
                    }
                },
                "transformer": {
                    "configuration": {
                        "component_type": "WanTransformer3DModel"
                    },
                    "quantization_config": {
                        "configuration": {
                            "config_type": "BitsAndBytesConfig"
                        },
                        "arguments": {
                            "load_in_4bit": true,
                            "bnb_4bit_quant_type": "{nf4}",
                            "bnb_4bit_compute_dtype": "torch.bfloat16"
                        }
                    },
                    "from_pretrained_arguments": {
                        "model_name": "variable:model_name",
                        "subfolder": "transformer",
                        "torch_dtype": "torch.bfloat16"
                    }
                },
                "transformer_2": {
                    "configuration": {
                        "component_type": "WanTransformer3DModel"
                    },
                    "quantization_config": {
                        "configuration": {
                            "config_type": "BitsAndBytesConfig"
                        },
                        "arguments": {
                            "load_in_4bit": true,
                            "bnb_4bit_quant_type": "{nf4}",
                            "bnb_4bit_compute_dtype": "torch.bfloat16"
                        }
                    },
                    "from_pretrained_arguments": {
                        "model_name": "variable:model_name",
                        "subfolder": "transformer_2",
                        "torch_dtype": "torch.bfloat16"
                    }
                },
                "text_encoder": {
                    "configuration": {
                        "component_type": "transformers.UMT5EncoderModel",
                        "device": "cpu"
                    },
                    "from_pretrained_arguments": {
                        "model_name": "variable:model_name",
                        "subfolder": "text_encoder",
                        "torch_dtype": "torch.bfloat16"
                    }
                },
                "from_pretrained_arguments": {
                    "model_name": "variable:model_name",
                    "torch_dtype": "torch.bfloat16"
                },
                "arguments": {
                    "prompt": "variable:prompt",
                    "guidance_scale": 4.0,
                    "guidance_scale_2": 3.0,
                    "num_frames": 121,
                    "width": 640,
                    "height": 480,
                    "num_inference_steps": "variable:num_inference_steps"
                }
            },
            "result": {
                "content_type": "video/mp4",
                "fps": 24
            }
        }
    ]
}